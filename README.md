# Multimodal-AI-App-using-Llava-7B
Multimodal AI App using Llava 7B and Gradio. Building an AI Voice Assistant App using Multimodal LLM "Llava" and Whisper.

## Description:
-  Dive into the fascinating world of generative AI as we build a cutting-edge voice assistant using the multimodal LLM "Llava 1.5 7B" for unparalleled image/text understanding capabilities, and the robust Whisper model by OpenAI for accurate speech-to-text conversion.
-  It showcases the integration of these technologies within a Gradio app, complemented by the gTTS library for realistic text-to-speech functionality bringing our voice assistant to life.
-  Build an AI Voice Assistant App using Multimodal LLM "Llava" and Whisper

## Implementation Expert Guide:
[Demo ‚ñ∂Ô∏è](https://www.youtube.com/watch?v=77dJJBFPLpY)

 ---
## ¬©Ô∏è License ü™™ 

Distributed under the MIT License. See `LICENSE` for more information.

---

#### **If you like this LLM Project do drop ‚≠ê to this repo**
#### Follow me on [![LinkedIn](https://img.shields.io/badge/linkedin-%230077B5.svg?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/gurpreetkaurjethra/) &nbsp; [![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/GURPREETKAURJETHRA/)

---
